Impact,Model,Title,Category,ArXiv Link,GitHub,ImageURL,Citation,Publication Date,Property,ID
,,open-interpreter,"Agent-Project, Code-LLM",,https://github.com/OpenInterpreter/open-interpreter,,,,,469
,,Mora: Enabling Generalist Video Generation via A Multi-Agent Framework,"Sora, Text-to-Video",https://arxiv.org/abs/2403.13248,,,,,,468
,,InternVideo2: Scaling Video Foundation Models for Multimodal Video Understanding,"ViFM, Video",https://arxiv.org/abs/2403.15377,https://github.com/OpenGVLab/InternVideo2/,,,,,466
,,awesome-korean-llm,"Awesome Repo, Korean",,https://github.com/NomaDamas/awesome-korean-llm,,,,,465
,,Awesome-Chinese-LLM,"Awesome Repo, Chinese",,https://github.com/HqWu-HITCS/Awesome-Chinese-LLM,,,,,464
,,Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation,Tex2Img,https://arxiv.org/abs/2403.16990,,,,,,463
,,LaVague,"Action-Model, Agent, LAM",,https://github.com/lavague-ai/LaVague,,,,,462
,,"DeliGrasp: Inferring Object Mass, Friction, and Compliance with LLMs for Adaptive and Minimally Deforming Grasp Policies",Robot,https://arxiv.org/abs/2403.07832,,,,,,461
,,Explorative Inbetweening of Time and Space,Temporal,https://arxiv.org/abs/2403.14611,,,,,,460
,,Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity,RAG,https://arxiv.org/abs/2403.14403,,,,,,459
,,"LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem",Agent,https://arxiv.org/abs/2312.03815,,,,,,458
,,AIOS: LLM Agent Operating System,Agent,https://arxiv.org/abs/2403.16971,,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSXFO2F4NIQ-EAzQYBBaPAYJQ0fHX64YfobmDIW5G6vsg&s,,,,457
,,RAFT: Adapting Language Model to Domain Specific RAG,RAG,https://arxiv.org/abs/2403.10131,,,,,,456
,,Gorilla: Large Language Model Connected with Massive APIs,"APIs, Agent, Tool",https://arxiv.org/abs/2305.15334,,https://gorilla.cs.berkeley.edu/assets/img/gorilla_method.png,,,,455
,,RAG-Fusion: a New Take on Retrieval-Augmented Generation,RAG,https://arxiv.org/abs/2402.03367,,,,,,454
,,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",RAG,,,,,,,453
,,Corrective Retrieval Augmented Generation,"CRAG, RAG",https://arxiv.org/abs/2401.15884,,,,,,452
,,Mamba: Linear-Time Sequence Modeling with Selective State Spaces,"Context-Window, Foundation",,,,,,,451
,,RoFormer: Enhanced Transformer with Rotary Position Embedding,Context-Window,,,,,,,449
,,Can large language models explore in-context?,In-Context-Learning,,,,,,,448
,,Prompt a Robot to Walk with Large Language Models,"Action-Generation, Generation, Prompting",,,,,,,446
,,ScreenAI: A Vision-Language Model for UI and Infographics Understanding,VLM,,,,,,,445
,,Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory01,"Agent, Minecraft",,,,,,,444
,,AgentTuning: Enabling Generalized Agent Abilities For LLMs,"Agent, Instruction-Turning",https://arxiv.org/abs/2310.12823,,,,,Comprehensive Collection of LLM-Related Papers,443
,,Chain of Code: Reasoning with a Language Model-Augmented Code Emulator,"Chain-of-Thought, Code-as-Policies",https://arxiv.org/abs/2312.04474,,,,,,442
,,OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following,"Agent, Embodied, Robot",,,,,,,441
,,Paper List for In-context Learning,"Awesome Repo, In-Context-Learning",,https://github.com/dqxiu/ICL_PaperList,,,,,440
,,IROS2023PaperList,"Awesome Repo, IROS, Robot",,https://github.com/gonultasbu/IROS2023PaperList,,,,,439
,,GPT-4V(ision) for Robotics: Multimodal Task Planning from Human Demonstration,"Demonstration, GPT4, PersonalCitation, Robot",,,,,,,438
,,Tree-Planner: Efficient Close-loop Task Planning with Large Language Models01,"LLM, PersonalCitation, Robot",,,,,,,437
,,DeepSeek-VL: Towards Real-World Vision-Language Understanding01,"VLM, VQA",,,,,,,436
,,Chain-of-table: Evolving tables in the reasoning chain for table understanding,"Chain-of-Thought, Reasoning, Table",,,,,,,435
,,On the Design Fundamentals of Diffusion Models: A Survey,"Diffusion, Survey",https://arxiv.org/abs/2306.04542,,,,,,434
,,Retrieval-Augmented Generation for Large Language Models: A Survey,"RAG, Survey",,,,,,,433
,,A Survey on Multimodal Large Language Models for Autonomous Driving,"Drive, Survey",https://arxiv.org/abs/2311.12320,,,,,,432
,,Video Understanding with Large Language Models: A Survey,"Survey, Video",,,,,,,431
,,Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements,"LoRA, Scaling",https://arxiv.org/abs/2305.03695,,,,,,429
,,Awesome LLM-Powered Agent,"Agent, Awesome Repo",,https://github.com/hyp1231/awesome-llm-powered-agent,,,,,428
,,LLM Agents Papers,"Agent, Awesome Repo",,https://github.com/zjunlp/LLMAgentPapers,,,,,427
,40,Cognitive Architectures for Language Agents,Agent,https://arxiv.org/abs/2309.02427,,,,,,426
30,,Awesome LLM Compression,"Awesome Repo, Compress",,https://github.com/HuangOwen/Awesome-LLM-Compression,,,,Awesome LLM Compression,424
,,A Survey on Model Compression for Large Language Models,"Compress, Quantization, Survey",https://arxiv.org/abs/2308.07633,,,,,,422
,,A latent text-to-image diffusion model,Diffusion,,,,,,,421
,,Robust Speech Recognition via Large-Scale Weak Supervision,Audio,,,,,,,420
,,Efficient Large Language Models: A Survey,Survey,https://arxiv.org/abs/2312.03863,https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey,,,,,419
,,LoRA: Low-Rank Adaptation of Large Language Models,"LoRA, Scaling",,,,,,,418
,,Alpaca-LoRA,Package,,https://github.com/tloen/alpaca-lora,,,,,417
,,Dify,Package,,https://github.com/langgenius/dify,,,,,416
60,,Awesome LLMOps,"Awesome Repo, Package",,https://github.com/tensorchord/Awesome-LLMOps,,,,,415
,,h2oGPT,Package,,https://github.com/h2oai/h2ogpt,,,,,414
,,LangChain,Package,,https://github.com/langchain-ai/langchain,,,,,413
,,LlamaIndex,Package,,https://github.com/run-llama/llama_index,,,,,412
,,(Long)LLMLingua: Enhancing Large Language Model Inference via Prompt Compression,"Compress, Scaling",https://arxiv.org/abs/2310.05736,,,,,,411
,,A Neuro-Mimetic Realization of the Common Model of Cognition via Hebbian Learning and Free Energy Minimization,Brain,,,,,,,410
,,Could a Large Language Model be Conscious?,"Brain, Conscious",,,,,,,409
,,Could a Large Language Model be Conscious?,"Brain, Conscious",,,,,,,408
,,Lenna: Language Enhanced Reasoning Detection Assistant,"Perception, Reasoning",https://arxiv.org/abs/2312.02433,,,,,,407
,,OCI-Robotics: Object-Centric Instruction Augmentation for Robotic Manipulation,Robot,https://arxiv.org/abs/2401.02814,,,,,,406
,,S-Agents: Self-organizing Agents in Open-ended Environment,"Agent, Minecraft",,,,,,,404
,,InCoRo: In-Context Learning for Robotics Control with Feedback Loops,"Feedback, In-Context-Learning, Robot",,,,,,,403
,,[Resource] arxiv-sanity,Resource,https://arxiv-sanity-lite.com/,,,,,,400
,,[Resource] AlphaSignal,Resource,https://alphasignal.ai/,,,,,,399
,,Imperial College London - Zeroshot trajectory,Lab,,,,,,,397
,,OpenGVLab,Lab,,https://github.com/OpenGVLab,,,,,396
,,Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook,"Survey, TimeSeries",,,,,,,395
,,Awesome Vision-Language Navigation,"Awesome Repo, Perception, VLM",,https://github.com/daqingliu/awesome-vln,,,,,394
70,,Awesome Large Multimodal Agents,"Agent, Awesome Repo",,https://github.com/jun0wanan/awesome-large-multimodal-agents,,,,,393
100,,Awesome-LLM-Survey,"Awesome Repo, LLM, Survey",,https://github.com/HqWu-HITCS/Awesome-LLM-Survey,,,,,392
,,A Survey on Data Selection for Language Models,"Datatset, LLM, Survey",,,,,,,391
,,A Survey on Knowledge Distillation of Large Language Models,"Distilling, Survey",,,,,,,390
,,"If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents","Agent, Code-LLM, Code-as-Policies, Survey",https://arxiv.org/abs/2401.00812,,,5,,,389
,,A Survey on Data Selection for LLM Instruction Tuning,"Instruction-Turning, Survey",,,,,,,388
,,Understanding LLMs: A Comprehensive Overview from Training to Inference,"Survey, Training",,,,3,,,387
,,Awesome-Papers-Autonomous-Agent,"Agent, Awesome Repo",,https://gh.mlsub.net/lafmdp/Awesome-Papers-Autonomous-Agent,,,,,386
,,Combating Misinformation in the Age of LLMs: Opportunities and Challenges,"Hallucination, Survey",https://arxiv.org/abs/2311.05656,,,,,,385
,,A Survey on In-context Learning,"In-Context-Learning, Survey",https://arxiv.org/abs/2301.00234,,,,,,384
,,[Resource] Semanticscholar,Resource,https://www.semanticscholar.org,,,,,,383
,,Self-Instruct: Aligning Language Models with Self-Generated Instructions,"Instruction-Turning, Self",,,,817,,,382
,,"""What’s important here?"": Opportunities and Challenges of Using LLMs in Retrieving Informatio from Web Interfaces","Agent, GUI, Web",,,,,,,381
,,SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents,"Agent, GUI",,,,,,,380
,,ScreenAgent: A Computer Control Agent Driven by Visual Language Large Model,"Agent, GUI",,https://github.com/niuzaisheng/ScreenAgent,,,,,379
,,LLM Powered Autonomous Agents,"Agent, Blog",https://lilianweng.github.io/posts/2023-06-23-agent/,,,,,,378
,,ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs,"Agent, Tool",,,,,,,377
,,AGENT INSTRUCTS LARGE LANGUAGE MODELS TO BE GENERAL ZERO-SHOT REASONERS,"Agent, Reasoning",,,,,,,376
,,Can Language Agents Approach the Performance of RL? An Empirical Study On OpenAI Gym,"Gym, PPO, Reinforcement-Learning, Survey",,,,,,,375
,,Embodied Task Planning with Large Language Models,"Agent, Embodied",,,,,,,374
,,"LEARNING EMBODIED VISION-LANGUAGE PRO- GRAMMING FROM INSTRUCTION, EXPLORATION, AND ENVIRONMENTAL FEEDBACK","Agent, Game",,,,,,,372
,,You Only Look at Screens: Multimodal Chain-of-Action Agents,"Agent, GUI, MobileApp",,,,,,,371
,,Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds,"Agent, Minecraft",,,,,,,370
,,Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University -  CogVLM,Lab,,,,,,,369
,,"Rutgers University, AGI Research - OpenAGI",Lab,,,,,,,368
,,Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation,"Chain-of-Thought, Reasoning",,,,,,,367
,,XLANG NLP Lab - OpenAgents,Lab,,,,,,,366
,,"OpenBMB - ChatDev, XAgent, AgentVerse",Lab,,,,,,,365
,,Reworkd AI - AgentGPT,Lab,,,,,,,364
,,DeepWisdom - MetaGPT,Lab,,,,,,,363
,,"Tencent AI Lab - AppAgent, WebVoyager",Lab,,,,,,,362
,,ChatGPT for Robotics: Design Principles and Model Abilities,"Code-as-Policies, PersonalCitation, Robot",,,,,,,361
,,RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks,"Code-as-Policies, PersonalCitation, Robot",,,,,,,360
,,Creative Robot Tool Use with Large Language Models,"Code-as-Policies, Robot",,,,,,,359
,,RoboScript: Code Generation for Free-Form Manipulation Tasks across Real and Simulation,"Code-as-Policies, Robot",,,,,,,358
,,Real-World Robot Applications of Foundation Models: A Review,"Robot, Survey",,,,,,,357
,,Correcting Robot Plans with Natural Language Feedback,"Feedback, Robot",https://arxiv.org/abs/2204.05186,,,,,,356
,,Segment and Caption Anything,"Anything, Caption, Perception, Segmentation",https://arxiv.org/abs/2312.00869,,https://d3i71xaburhd42.cloudfront.net/339ec34efdccdf2bf43bb817ef7cab5058bfa2e7/1-Figure1-1.png,,,,355
,,3D Diffusion Policy,"Diffusion, Robot",https://arxiv.org/abs/2403.03954,,,,,,354
,,Autonomous Agents,"Agent, Awesome Repo",,https://github.com/tmgthb/Autonomous-Agents,,,,,353
,,PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization,Agent,,,,,,,352
,,Awesome Embodied Vision,"Awesome Repo, Embodied",,https://github.com/ChanganVR/awesome-embodied-vision,,,,,351
,,GLaMM: Pixel Grounding Large Multimodal Model,Grounding,,,,,,,349
,,V-IRL: Grounding Virtual Intelligence in Real Life,Grounding,,,,,,,348
,,Visually Grounded Reasoning across Languages and Cultures,"Grounding, Reasoning",,,,,,,347
,,Visual Prompt Tuning,"In-Context-Learning, Prompt-Tuning",,,,,,,346
,,Prompting Visual-Language Models for Efficient Video Understanding,"In-Context-Learning, Video",,,,,,,345
,,Visual Prompting via Image Inpainting,"In-Context-Learning, Vision",,,,,,,344
,,What Makes Good Examples for Visual In-Context Learning?,"In-Context-Learning, Vision",,,,,,,343
,,What does CLIP know about a red circle? Visual prompt engineering for VLMs,In-Context-Learning,,,,,,,342
,,Visual In-Context Prompting,"In-Context-Learning, Perception, Vision",,,https://i.ytimg.com/vi/6_xjjbaKwjA/maxresdefault.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGBcgVCh_MA8=&rs=AOn4CLCLIKY7b56LPzhA1vl0k8RS1jgN4w,,,,341
,,SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding,Perception,,,,,,,340
,,LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models,"Image, LLaMA, Perception",,,,,,,339
,,CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval,"Perception, Video, Vision",https://arxiv.org/abs/2104.08860,,,,,,338
,,Secrets of RLHF in Large Language Models Part II: Reward Modeling,RLHF,,,,,,,337
,,Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale,"In-Context-Learning, Scaling",,,,18,2022/03/06,,336
,,"Structured Prompting: Scaling In-Context Learning to 1,000 Examples","In-Context-Learning, Scaling",,,,20,2020/03/06,,335
,,Tuna: Instruction Tuning using Feedback from Large Language Models,Instruction-Turning,https://arxiv.org/abs/2310.13385,,,,2023/03/06,,334
,,In-Context Instruction Learning,"In-Context-Learning, Instruction-Turning",,,https://pbs.twimg.com/media/FqGlB2lWwAAPyX3.jpg,,,,333
,,Exploring the Benefits of Training Expert Language Models over Instruction Tuning,Instruction-Turning,https://arxiv.org/abs/2302.03202,,,27,2023/02/06,,332
,,"AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn",Agent,,,,,,,331
,,OpenAGI: When LLM Meets Domain Experts,"AGI, Agent",,,,54,,,330
,,A Closer Look at the Limitations of Instruction Tuning,"Instruction-Turning, Survey",https://arxiv.org/abs/2402.05119,,,,,,329
,,The Impact of Reasoning Step Length on Large Language Models,Reasoning,,,,,,,328
,,STaR: Bootstrapping Reasoning With Reasoning,Reasoning,https://arxiv.org/abs/2203.14465,,,,2022/05/28,,327
,,"LONGNET: Scaling Transformers to 1,000,000,000 Tokens",Scaling,https://arxiv.org/abs/2307.02486,,,,2023/07/01,,325
,,Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,"Context-Window, Foundation, Gemini, LLM, Scaling",,,,,,,324
,,Secrets of RLHF in Large Language Models Part I: PPO,"PPO, RLHF, Reinforcement-Learning",https://arxiv.org/abs/2402.01030,,,,2024/02/01,,323
,,EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions,"Audio2Video, Diffusion, Generation, Video",,,,,,,322
,,VisionLLaMA: A Unified LLaMA Interface for Vision Tasks,"Foundation, LLaMA, Vision",,,https://media.licdn.com/dms/image/D4E12AQEs7aGgeapSdw/article-inline_image-shrink_1000_1488/0/1709592515484?e=2147483647&v=beta&t=gMRatq5gkN4ofk2WK5-jbVEWVqq0tgloCTRBJY7QiI8,,,,321
,,NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models,"Diffusion, Speech",,,,,,,320
,,Learning to Model the World with Language,World-model,https://arxiv.org/abs/2308.01399,,https://preview.redd.it/learning-to-model-the-world-with-language-uc-berkeley-2023-v0-8kluures85gb1.jpg?width=1358&format=pjpg&auto=webp&s=1f8b9a5c83f3e911ee170de7726cd2ee46262f74,,,,319
,,Executable Code Actions Elicit Better LLM Agents,"Code-as-Policies, Robot",,,,,,,317
70,,XLang Paper Reading,"Agent, Awesome Repo, Embodied, Grounding",,https://github.com/xlang-ai/xlang-paper-reading,,,,,316
,,ScreenAgent: A Vision Language Model-driven Computer Control Agent,Agent,,,,,,,315
,,Design2Code: How Far Are We From Automating Front-End Engineering?,"Code-LLM, Front-End",,,,,,,314
,,Simple Open-Vocabulary Object Detection with Vision Transformers,Perception,https://arxiv.org/abs/2205.06230,,,,,,313
,,Application of Pretrained Large Language Models in Embodied Artificial Intelligence,"Agent, Embodied, Survey",https://www.semanticscholar.org/paper/Application-of-Pretrained-Large-Language-Models-in-Kovalev-Panov/04f87baf7d1b3eb303a52a8a66c8189f396dd114,,,,,,312
,,RT-H: Action Hierarchies Using Language,"Natural-Language-as-Polices, Robot",https://arxiv.org/abs/2403.01823,,,,,,311
,,Demo2Code: From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought,"Chain-of-Thought, Code-as-Policies, PersonalCitation, Robot",https://arxiv.org/abs/2305.16744,,,,,,310
,,PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs,Robot,https://arxiv.org/abs/2402.07872,,,,,,309
,,Diffusion World Model,World-model,https://arxiv.org/abs/2402.03570,,,,,,308
,,Learning to Model the World with Language,World-model,https://arxiv.org/abs/2308.01399,,,,,,307
,,Language Models Meet World Models,World-model,https://arxiv.org/abs/2305.10626,,,,,,306
,,Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,MoE,https://arxiv.org/abs/2101.03961,,,,,,305
,,Training Language Models with Memory Augmentation,RAG,,,,,,,304
,,RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents,"Agent, Memory, RAG",https://arxiv.org/abs/2402.03610,,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ_QDJp6ApwRN6jlDLF7cOSVfD1TmXT_ZS72sniqN5caw&s,,2024/02/06,,303
,,[Resource] Connectedpapers,Resource,https://www.connectedpapers.com/,,,,,,302
,,Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models,"Datatset, Instruction-Turning",,,,,,,301
,,Exploring Format Consistency for Instruction Tuning,Instruction-Turning,,,,,,,300
,,INSTRUCTION TUNING WITH GPT-4,"GPT4, Instruction-Turning",https://arxiv.org/abs/2304.03277,,,,,,299
,,REVO-LION: EVALUATING AND REFINING VISION LANGUAGE INSTRUCTION TUNING DATASETS,"Datatset, Instruction-Turning",,,,,,,298
,,A Closer Look at the Limitations of Instruction Tuning,Instruction-Turning,,,,,,,297
,,Vision-Language Instruction Tuning: A Review and Analysis,"Instruction-Turning, Survey",,,,,,,296
,,Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning,"Instruction-Turning, Survey",,,,,,,295
,,Executable Code Actions Elicit Better LLM Agents,"Agent, Code-as-Policies",https://arxiv.org/abs/2402.01030,,,,2024/01/24,,294
,,Chain of Code: Reasoning with a Language Model-Augmented Code Emulator,"Code-as-Policies, Reasoning",,,,,,,293
,,Octopus: Embodied Vision-Language Programmer from Environmental Feedback,"Agent, Embodied",,,,,,,292
,,Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld,"Agent, Embodied",https://arxiv.org/abs/2311.16714,,,,,,291
,,RoboCodeX:Multi-modal Code Generation forRobotic Behavior Synthesis,"Code-as-Policies, PersonalCitation, Robot",https://arxiv.org/abs/2402.16117,,,,,,290
,,Large Language Models for Robotics: A Survey,"LLM, Robot, Survey",,,,,,,289
,,Pangu-Agent: A Fine-Tunable Generalist Agent with Structured Reasoning,"Agent, Reasoning",,,,,,,288
,,You Only Look at Screens: Multimodal Chain-of-Action Agents,"Agent, MobileApp",,https://github.com/cooelf/Auto-UI,,,,,287
,,[Resource] dailyarxiv,Resource,https://dailyarxiv.com/,,,,,,285
,,Symbol-LLM: Leverage Language Models for Symbolic System in Visual Human Activity Reasoning,"Reasoning, Symbolic",,,,,,,284
,,Large Multimodal Agents: A Survey,"Agent, Survey",,,,,,,283
,,Agent AI: Surveying the Horizons of Multimodal Interaction,"Agent, Survey",,,,,,,282
,,Instruction Tuning for Large Language Models: A Survey,"Instruction-Turning, LLM, Survey",,,,,,,281
,,A Survey of Reinforcement Learning from Human Feedback,"RLHF, Reinforcement-Learning, Survey",,,,,,,280
90,,Multimodal & Large Language Models,"Awesome Repo, LLM, VLM",,https://github.com/Yangyi-Chen/Multimodal-AND-Large-Language-Models,,,,,279
,,Introspective Tips: Large Language Model for In-Context Decision Making,Robot,https://www.semanticscholar.org/paper/Introspective-Tips%3A-Large-Language-Model-for-Making-Chen-Wang/047e3812854a86b2a2e113219fa956eda860ce24,,,,,,278
,,AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation,"Reasoning, Robot",,,,,,,277
,,Gorilla: Large Language Model Connected with Massive APIs,"Agent, Tool",,,,,,,276
,,[Resource] huggingface,Resource,https://huggingface.co/papers,,,,,,275
,,[Resource] Paperswithcode,Resource,https://paperswithcode.com/,,,,,,274
,,Language Models Meet World Models: Embodied Experiences Enhance Language Models,"Embodied, World-model",,,,,,,273
,,RoFormer: Enhanced Transformer with Rotary Position Embedding,RoPE,https://arxiv.org/abs/2104.09864,,,,,,272
,,RoboCat: A Self-Improving Generalist Agent for Robotic Manipulation,Robot,,,,,,,271
,,Resonance RoPE: Improving Context Length Generalization of Large Language Models,"Context-Window, Reasoning, RoPE, Scaling",,,,,,,270
,,Learning and Leveraging World Models in Visual Representation Learning,World-model,,,,,,,269
,,Large World Model,"VLM, World-model",https://arxiv.org/abs/2402.08268,,,,,,268
,,Language Segment-Anything,"Perception, Robot",,,,,,,267
,,EgoCOT: Embodied Chain-of-Thought Dataset for Vision Language Pre-training,"Chain-of-Thought, Embodied, Robot",,,,,,,266
,,LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models01,"Benchmark, Sora, Text-to-Video",,,,,,,265
,,TaskWeaver: A Code-First Agent Framework,"Agent, Code-LLM",,,,,,,264
,,Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes01,Distilling,,,,,,,263
,,MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT,"LLaMA, Lightweight, Open-source",,,,,,,262
,,"Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models","Sora, Text-to-Video",,,,,,,261
,,StarCoder 2 and The Stack v2: The Next Generation,Code-LLM,,,,,,,260
,,Code as Reward: Empowering Reinforcement Learning with VLMs,"Code-as-Policies, Reinforcement-Learning, Reward",https://arxiv.org/abs/2402.04764,,,,,,259
,,Can Foundation Models Perform Zero-Shot Task Specification For Robot Manipulation?,Zero-shot,,,,,,,258
,,Large Language Models are Zero-Shot Reasoners,"Reasoning, Zero-shot",,,,,,,257
,,Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning,"Robot, Zero-shot",,,,,,,256
,,Mirage: Cross-Embodiment Zero-Shot Policy Transfer with Cross-Painting,"Robot, Zero-shot",,,,,,,255
80,,Language Models as Zero-Shot Trajectory Generators,"LLM, PersonalCitation, Robot, Zero-shot",https://arxiv.org/abs/2310.11604,,"https://static.wixstatic.com/media/a40efa_2fa8ef4839fe4cacb8a1e85655103a90~mv2.png/v1/fill/w_945,h_481,al_c,q_90,usm_0.66_1.00_0.01,enc_auto/pipeline.png",,,,254
,,Towards Generalizable Zero-Shot Manipulationvia Translating Human Interaction Plans,"Generation, Robot, Zero-shot",,,,,,,253
,,Zero-Shot Robotic Manipulation with Pretrained Image-Editing Diffusion Models,"Generation, Robot, Zero-shot",https://arxiv.org/abs/2310.10639,,,,,,252
,,OS-Copilot: Towards Generalist Computer Agents with Self-Improvement,"Agent, Web",https://arxiv.org/abs/2402.07456,,,,,,251
,,Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models,Reasoning,,,,,,,250
,,Rephrase and Respond(RaR),Reasoning,,,,,,,249
,,"Retrieval-Augmented Generation for Large Language ","RAG, Survey",,,,,,,248
,,Contrastive Chain-of-Thought Prompting,Reasoning,,,,,,,247
,,DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models,"Math, Reasoning",,,,,,,246
,,A Survey on Evaluation of Large Language Models,"Evaluation, LLM, Survey",https://arxiv.org/abs/2307.03109,,,,,,245
,,Advances in 3D Generation: A Survey,"Generation, Survey",,,,,,,244
,,Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens,"Context-Window, Scaling",,,,,,,243
,,"A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions","Awesome Repo, Hallucination, Survey",https://arxiv.org/abs/2311.05232,https://github.com/LuckyyySTA/Awesome-LLM-hallucination,,,,,242
,,Generative Expressive Robot Behaviors using Large Language Models,Robot,,,,,,,241
,,SliceGPT: Compress Large Language Models by Deleting Rows and Columns,"Quantization, Scaling",,,,,,,240
,,"Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs","Diffusion, Text-to-Image",,,,,,,239
,,Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data,"Anything, Depth",,,,,,,238
,,ReFT: Reasoning with Reinforced Fine-Tuning,"Reasoning, Reinforcement-Learning",,,,,,,237
,,MM-LLMs: Recent Advances in MultiModal Large Language Models,"Survey, VLM",,,,,,,235
,,Chain-of-Thought Reasoning Without Prompting,Reasoning,https://arxiv.org/abs/2402.10200,,,,,,234
,,Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots,"Robot, Zero-shot",,,,,,,233
,,Awesome-Diffusion-Models,"Awesome Repo, Diffusion",,https://github.com/diff-usion/Awesome-Diffusion-Models,,,,,232
,,Learning to Learn Faster from Human Feedback with Language Model Predictive Control,"Feedback, Robot",,,,,,,231
,,Gemma: Introducing new state-of-the-art open models,Open-source,https://blog.google/technology/developers/gemma-open-models/,,,,,,230
,,swarms,Agent,,https://github.com/kyegomez/swarms,,,,,229
50,,LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens,"Context-Window, LLM, RoPE, Scaling",https://arxiv.org/abs/2402.13753,,https://preview.redd.it/longrope-extending-llm-context-window-beyond-2-million-v0-dkyu60td2dkc1.jpg?width=1109&format=pjpg&auto=webp&s=a59c7ac6c1d8360450ddc4e121ed1150f4793cf0,,,,228
,,LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models,"Agent, LLM, Planning",,,,,,,227
,,Video as the New Language for Real-World Decision Making,"Agent, Video-for-Agent",,,,,,,226
,OmniACT,OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web,"Agent, Web",https://arxiv.org/abs/2402.17553,,,,,,225
,,Recognize Anything: A Strong Image Tagging Model,Perception,https://arxiv.org/abs/2306.03514,,,,,,224
,,TinyLLaVA: A Framework of Small-scale Large Multimodal Models,"LLaVA, VLM",https://arxiv.org/abs/2402.14289,,,,,,223
,,Large Language Models for Information Retrieval: A Survey,"RAG, Survey",,,,,,,222
,,FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation,"RAG, Temporal Logics",https://arxiv.org/abs/2310.03214,,,,,,221
,,BitNet: Scaling 1-bit Transformers for Large Language Models,"LLM, Scaling",https://arxiv.org/abs/2310.11453,,,,,,220
70,,The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits,"LLM, Quantization",https://arxiv.org/abs/2402.17764,,,,,,219
,,Awesome-LLM-Papers-Toward-AGI,"AGI, Awesome Repo, Survey",,https://github.com/shure-dev/Awesome-LLM-Papers-Toward-AGI,,,,,218
,NLaP,Natural Language as Polices: Reasoning for Coordinate-Level Embodied Control with LLMs,"Embodied, Reasoning, Robot",https://arxiv.org/abs/2403.13801,https://github.com/shure-dev/NLaP,,,2024/03/20,,217
,,Segment Anything,"Anything, Perception, Segmentation",https://arxiv.org/abs/2304.02643,,,,,,216
,,Reasoning Grasping via Multimodal Large Language Model,"Perception, Reasoning, Robot",https://arxiv.org/abs/2402.06798,,,,,,215
,BC-Z,BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning,"Robot, Zero-shot",https://arxiv.org/abs/2202.02005,,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQOGz8vcNIUjIZmwpap0f2epSp-wM7IMuRoj1Huk-2_&s,,,,214
,,Awesome AI Agents,"Agent, Awesome Repo",,https://github.com/e2b-dev/awesome-ai-agents,,,,,213
,,CoALA: Awesome Language Agents,"Agent, Awesome Repo, LLM",,https://github.com/ysymyth/awesome-language-agents,,,,,212
,,LLM-in-Vision,"Awesome Repo, LLM, Vision",,https://github.com/DirtyHarryLYL/LLM-in-Vision,,,,,211
,,Awesome RLHF (RL with Human Feedback),"Awesome Repo, RLHF, Reinforcement-Learning",,https://github.com/opendilab/awesome-RLHF,,,,,210
,,Chain-of-ThoughtsPapers,"Awesome Repo, Chain-of-Thought",,https://github.com/Timothyxxx/Chain-of-ThoughtsPapers,,,,,209
,,LLM-Leaderboard,"Awesome Repo, LLM, Leaderboard",,https://github.com/LudwigStumpp/llm-leaderboard,,,,,208
,,日本語LLMまとめ,"Awesome Repo, Japanese, LLM",,https://github.com/llm-jp/awesome-japanese-llm,,,,,207
,,World Model on Million-Length Video And Language With RingAttention,"Text-to-Image, World-model",,,,,,,206
,,DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection,Perception,,,,,,,205
,,Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection,"Open-source, Perception",,,,,,,204
,,"GPT-4V(ision) is a Generalist Web Agent, if Grounded","Agent, GPT4, Web",,,https://arxiv.org/html/2401.01614v1/x1.png,,,,203
,,Agents: An Open-source Framework for Autonomous Language Agents,Agent,,,,,,,202
,,SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding,"Anything, CLIP, Perception",,,,,,,201
,,A Survey on LLM-based Autonomous Agents,"Agent, Survey",,https://github.com/Paitesanshi/LLM-Agent-Survey,,,,,200
,,Levels of AGI: Operationalizing Progress on the Path to AGI,"AGI, Survey",,,,,,,199
,,Contrastive Chain-of-Thought Prompting,Prompting,,,,,,,198
,LARP,LARP: Language-Agent Role Play for Open-World Games,"Agent, Minecraft",,,,,,,197
,,Self-Discover: Large Language Models Self-Compose Reasoning Structures,Reasoning,,,,,,,196
,,WebLINX: Real-World Website Navigation with Multi-Turn Dialogue,"Agent, Web",,,,,,,195
,,Chain-of-Thought Reasoning Without Prompting,"Chain-of-Thought, Prompting",,,,,,,194
,,A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications,"Prompting, Survey",,,,,,,193
,,WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models,"Agent, Web",,,,,,,192
,Mobile-Agent,Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception,"Agent, GUI, MobileApp",,,,,,,191
,,OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics,Robot,,,,,,,190
,,Awesome-LLM,"Awesome Repo, LLM",,https://github.com/Hannibal046/Awesome-LLM,,,,,189
,,Awesome-Reasoning-Foundation-Models,"Awesome Repo, Reasoning",,https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models,,,,,188
,,Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning,"Grounding, Reinforcement-Learning",,,,,,,187
50,,Everything-LLMs-And-Robotics,"Awesome Repo, LLM, Robot",,https://github.com/jrin771/Everything-LLMs-And-Robotics,,,,,186
,,War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars,"Agent, Multi",https://arxiv.org/abs/2311.17227,,,,,,185
,,Awesome-Multimodal-LLM,"Awesome Repo, Multimodal",,https://github.com/Atomic-man007/Awesome_Multimodel_LLM,,,,,184
,,LLMSurvey,"Awesome Repo, Survey",,https://github.com/RUCAIBox/LLMSurvey,,,,,183
,,Awesome LLM Reasoning,"Awesome Repo, Reasoning",,https://github.com/atfortes/Awesome-LLM-Reasoning,,,,,182
,,Awesome-LLM-Robotics,"Awesome Repo, Robot",,https://github.com/GT-RIPL/Awesome-LLM-Robotics,,,,,181
90,,Awesome-Embodied-Agent-with-LLMs,"Agent, Awesome Repo, LLM",,https://github.com/zchoi/Awesome-Embodied-Agent-with-LLMs,,,,,180
,,Awesome-Multimodal-Large-Language-Models,"Awesome Repo, Multimodal",,https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models,,,,,179
,AppAgent,AppAgent: Multimodal Agents as Smartphone Users,"Agent, GUI, MobileApp",,,,,,,178
,,Embodied Question Answering,Enbodied,https://arxiv.org/abs/1711.11543,,,,,,177
,DetGPT,DetGPT: Detect What You Need via Reasoning,"Perception, Reasoning",https://arxiv.org/abs/2305.14167,,,,,,176
,MindAgent,MindAgent: Emergent Gaming Interaction,Agent,,,,,,,175
,,LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models,"Agent, Embodied",,,,,,,174
,,STARLING: SELF-SUPERVISED TRAINING OF TEXTBASED REINFORCEMENT LEARNING AGENT WITH LARGE LANGUAGE MODELS,"Agent, Reinforcement-Learning",,,,,,,173
,,Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning,World-model,,,,,,,172
,NavGPT,NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models,"Navigation, Reasoning, Vision",,,,,,,171
,InfiAgent,InfiAgent: A Multi-Tool Agent for AI Operating Systems,Agent,,,,,,,170
,,Predictive Minds: LLMs As Atypical Active Inference Agents,Agent,,,,,,,169
,,When Brain-inspired AI Meets AGI,"AGI, Brain",,,,,,,168
,,Sparks of Artificial General Intelligence: Early experiments with GPT-4,"Benchmark, GPT4",,,,,,,167
,,An Interactive Agent Foundation Model,"Agent, End2End, Game, Robot",https://arxiv.org/abs/2402.05929,,,,,,165
,XAgent,XAgent: An Autonomous Agent for Complex Task Solving,Agent,,,,,,,164
,RoCo,RoCo: Dialectic Multi-Robot Collaboration with Large Language Models,Robot,https://arxiv.org/abs/2307.04738,,,25,,,162
,CogAgent,CogAgent: A Visual Language Model for GUI Agents,"Agent, GUI",,,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQF5VhNYFxjBT3fzwDAwvxsYEYw6yUbJhUDFrO8RBKSfQ&s,,,,161
,,LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination,Agent,,,,,,,160
70,,Divergences between Language Models and Human Brains,"AGI, Brain",,,,,,,159
,,LLM-BRAIn: AI-driven Fast Generation of Robot Behaviour Tree based on Large Language Model,Brain,,,,,,,158
,,Instruction-tuning Aligns LLMs to the Human Brain,"Brain, Instruction-Turning",,,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTRO7ny6B0ZVTmaDx6AhdWwo5IHbmatnD4FNe7-1ZTDng&s,,,,157
,,Large Language Models Are Semi-Parametric Reinforcement Learning Agents,Reinforcement-Learning,,,,,,,156
,RLang,RLang: A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents,Reinforcement-Learning,,,,,,,155
,,Semantic HELM: A Human-Readable Memory for Reinforcement Learning,"Memory, Reinforcement-Learning",,,,,,,154
,,AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents,"In-Context-Learning, Reinforcement-Learning",,,,,,,153
,AgentVerse,AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors,Agent,https://arxiv.org/abs/2308.10848,,,,,,152
,Agents,Agents: An Open-source Framework for Autonomous Language Agents,Agent,https://arxiv.org/abs/2309.07870,https://github.com/aiwaves-cn/agents,,,,,151
,OpenAgents,OpenAgents: An Open Platform for Language Agents in the Wild,"Agent, Embodied",https://arxiv.org/abs/2310.10634,https://github.com/xlang-ai/OpenAgents,,,,,150
,AutoAgents,AutoAgents: A Framework for Automatic Agent Generation,Agent,,https://github.com/Link-AGI/AutoAgents,,,,,149
,DSPy,DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines,Agent,https://arxiv.org/abs/2310.03714,,,,,,148
,AutoGen,AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,Agent,,,,,,,147
,CAMEL,CAMEL: Communicative Agents for “Mind” Exploration of Large Language Model Society,Agent,,,,,,,146
,babyagi,,Agent,,https://github.com/yoheinakajima/babyagi,,,,,145
,XAgent,XAgent: An Autonomous Agent for Complex Task Solving,Agent,https://blog.x-agent.net/blog/xagent/,,,,,,144
,ChatDev,Communicative Agents for Software Development,"Agent, Soft-Dev",,https://github.com/OpenBMB/ChatDev,,,,,143
,MetaGPT,MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework,"Agent, Soft-Dev",,,,,,,142
,llama-gpt,"A self-hosted, offline, ChatGPT-like chatbot, powered by Llama 2. 100% private, with no data leaving your device.","LLM, Open-source",,https://github.com/getumbrel/llama-gpt,,,,,141
,Selection-Inference,Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning,Reasoning,https://arxiv.org/abs/2205.09712,,,,,,140
,ReConcile,ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.,Reasoning,,,,,,,132
,Code LLaMA,Code Llama: Open Foundation Models for Code,"Foundation, LLM, Open-source",,,,,,,131
,,Interactive Language: Talking to Robots in Real Time,Robot,,,,,,,130
,,Large Language Models as Generalizable Policies for Embodied Tasks,"Embodied, Robot",,,,,,,129
,,Look Before You Leap: Unveiling the Power ofGPT-4V in Robotic Vision-Language Planning,"Chain-of-Thought, GPT4, Reasoning, Robot",https://robot-vila.github.io/ViLa.pdf,,,,2023/11/29,,128
,,AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents,"Agent, Embodied, Robot",https://arxiv.org/abs/2401.12963,,,,,,127
,,Generative Agents: Interactive Simulacra of Human Behavior,Agent,https://arxiv.org/abs/2304.03442,,,,,,126
,,Learning to Compress Prompts with Gist Tokens,"Compress, Prompting",https://arxiv.org/abs/2304.08467,,,,,,125
,,Reasoning with Language Model Prompting: A Survey,"Reasoning, Survey",https://arxiv.org/abs/2212.09597,,,,,,124
,,Large Language Models are few(1)-shot Table Reasoners,"Reasoning, Table",https://arxiv.org/abs/2210.06710,,,,,,123
,,GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation,"3D, GPT4, VLM",https://arxiv.org/abs/2401.04092,,,,,,122
,,Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2401.04398,,,,,,121
,,Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters,"Chain-of-Thought, Reasoning, Survey",https://arxiv.org/abs/2212.10001,,,,2023/12/20,,120
,,Inner Monologue: Embodied Reasoning through Planning with Language Models,"Code-as-Policies, Embodied, PersonalCitation, Reasoning, Robot, Task-Decompose",https://arxiv.org/abs/2207.05608,,https://innermonologue.github.io/img/teaser.png,,,,119
,,Text2Motion: From Natural Language Instructions to Feasible Plans,"PersonalCitation, Robot",https://arxiv.org/abs/2303.12153,,,,,,118
,SayCan,"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances","LLM, Robot, Task-Decompose",https://arxiv.org/abs/2204.01691,,,,2022/04/04,Decomposing task,117
,Multimodal-CoT,Multimodal Chain-of-Thought Reasoning in Language Models,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2302.00923,,,,2023/02/02,Chain of Thought,116
,LiDAR-LLM,LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding,"Perception, Robot",https://arxiv.org/abs/2312.14074,,,,2023/12/21,Multimodal Data injection,115
,APE,Large Language Models Are Human-Level Prompt Engineers,"Automate, Prompting",https://arxiv.org/abs/2211.01910,,,,2022/11/03,Automation,114
,Self-Consistency,Self-Consistency Improves Chain of Thought Reasoning in Language Models,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2203.11171,,,,2022/03/21,Reasoning,113
,Skeleton-of-Thought,Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2307.15337,,,,2023/07/28,Chain of Thought,112
,EmbodiedGPT,EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought,"Chain-of-Thought, Embodied, PersonalCitation, Robot, Task-Decompose",https://arxiv.org/abs/2305.15021,,https://d3i71xaburhd42.cloudfront.net/00cb69a9f280317d1c59ac5827551ee9b10642b8/4-Figure2-1.png,,2023/05/24,Chain of Thought,111
,Rethinking with Retrieval,Rethinking with Retrieval: Faithful Large Language Model Inference,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2301.00303,,,,2022/12/31,Chain of Thought,110
,InstructGPT,Training language models to follow instructions with human feedback,"Instruction-Turning, LLM",https://arxiv.org/abs/2203.02155,,,,2022/03/04,,109
,LLaMA-adapter,LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention,"Instruction-Turning, LLM, PEFT",https://arxiv.org/abs/2303.16199,,,,2023/03/28,,108
,Robotic Brain,LLM as A Robotic Brain: Unifying Egocentric Memory and Control,"Memory, Robot",https://arxiv.org/abs/2304.09349,,,,2023/04/19,Brain,107
,GLIP,Grounded Language-Image Pre-training,Perception,https://arxiv.org/abs/2112.03857,,,,2021/12/07,Object Detection,106
,Instruct2Act,Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model,"Code-as-Policies, Multimodal, OpenGVLab, PersonalCitation, Robot",https://arxiv.org/abs/2305.11176,,https://miro.medium.com/v2/resize:fit:1096/1*EIUFVxb1Dri0EaYECy-JHg.png,,2023/05/18,Multimodal prompts,105
,Language Instructed Reinforcement Learning,Language Instructed Reinforcement Learning for Human-AI Coordination,"Agent, Reinforcement-Learning",https://arxiv.org/abs/2304.07297,,,,2023/04/13,Reinforcement Learning,104
,Self-Instruct,Self-Instruct: Aligning Language Models with Self-Generated Instructions,"Instruction-Turning, LLM",https://arxiv.org/abs/2212.10560,,,,2022/12/20,,103
,ChatEval,ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate,In-Context-Learning,https://arxiv.org/abs/2308.07201,,,,2023/08/14,Memory,102
,MemoryBank,MemoryBank: Enhancing Large Language Models with Long-Term Memory,"LLM, Memory",https://arxiv.org/abs/2305.10250,,,,2023/05/17,Memory,101
,Statler,Statler: State-Maintaining Language Models for Embodied Reasoning,"Code-as-Policies, PersonalCitation, Robot, State-Manage",https://arxiv.org/abs/2306.17840,,,,2023/06/30,Code generation,100
,VISPROG,Visual Programming: Compositional visual reasoning without training,"Code-as-Policies, VLM, VQA",https://arxiv.org/abs/2211.11559,,,,2022/11/18,Visual Question Answering,99
,Chain-of-Thought Hub,Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2305.17306,,,,2023/05/26,Benchmark,98
,ReAct,ReAct: Synergizing Reasoning and Acting in Language Models,In-Context-Learning,https://arxiv.org/abs/2303.11366,,,,2023/03/20,Reasoning,97
,SayTap,SayTap: Language to Quadrupedal Locomotion,"Low-level-action, Robot",https://arxiv.org/abs/2306.07580,,,,2023/06/13,Low-level output,96
,Progprompt,ProgPrompt: Generating Situated Robot Task Plans using Large Language Models,"Code-as-Policies, PersonalCitation, Robot",https://arxiv.org/abs/2209.11302,,,,2022/09/22,Code generation,95
,Language-conditioned,Language-conditioned Learning for Robotic Manipulation: A Survey,"Robot, Survey",https://arxiv.org/abs/2312.10807,,,,2023/12/17,Survey papers,94
,InstructBLIP,InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning,"LLM, Open-source",https://arxiv.org/abs/2305.06500,,,,2023/05/11,Open sourced LLM,93
80,LLaMA,LLaMA: Open and Efficient Foundation Language Models,"Foundation, LLM, Open-source",https://arxiv.org/abs/2302.13971,,,,2023/02/27,Open sourced LLM,92
,GPT4,GPT-4 Technical Report,"GPT4, LLM",https://arxiv.org/abs/2303.08774,,,,2023/03/15,Closed sourced LLM,91
,Socratic,Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language,"Code-as-Policies, PersonalCitation, Robot, Zero-shot",https://arxiv.org/abs/2204.00598,,,,2022/04/01,Code generation,90
,GPT3,Language Models are Few-Shot Learners,LLM,https://arxiv.org/abs/2005.14165,,,,2020/05/28,Closed sourced LLM,89
,PlanBench,PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change,"Benchmark, In-Context-Learning",https://arxiv.org/abs/2206.10498,,,,2022/06/21,Benchmark,88
,SayPlan,SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning,"Robot, Task-Decompose",https://arxiv.org/abs/2307.06135,,,,2023/07/12,Decomposing task,87
,Reasoning via Planning,Reasoning with Language Model is Planning with World Model,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2305.14992,,,,2023/05/24,Reasoning,86
,LLM+P,LLM+P: Empowering Large Language Models with Optimal Planning Proficiency,Agent,https://arxiv.org/abs/2304.11477,,,,2023/04/22,Planning,85
,Grounding DINO,Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection,Perception,https://arxiv.org/abs/2303.05499,,,,2023/03/09,Object Detection,84
,Language Models as Zero-Shot Planners,Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents,"Robot, Task-Decompose, Zero-shot",https://arxiv.org/abs/2201.07207,,,,2022/01/18,Decomposing task,83
,ARB,ARB: Advanced Reasoning Benchmark for Large Language Models,"Benchmark, In-Context-Learning",https://arxiv.org/abs/2307.13692,,,,2023/07/25,Benchmark,82
,GATO,A Generalist Agent,"Agent, Multimodal, Robot",https://arxiv.org/abs/2205.06175,,,,2022/05/12,Multimodal LLM,81
,Foundation Models,"Foundation Models in Robotics: Applications, Challenges, and the Future","Foundation, Robot, Survey",https://arxiv.org/abs/2312.07843,,,,2023/12/13,Survey papers,80
,RoboGen,RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation,"Data-generation, Robot",https://arxiv.org/abs/2311.01455,,,,2023/11/02,Data generation,79
,EAGER,EAGER: Asking and Answering Questions for Automatic Reward Shaping in Language-guided RL,"Agent, Reinforcement-Learning, Reward",https://arxiv.org/abs/2206.09674,,,,2022/06/20,Reinforcement Learning,78
,FLAN,Finetuned Language Models Are Zero-Shot Learners,"Instruction-Turning, LLM, Zero-shot",https://arxiv.org/abs/2109.01652,,,,2021/09/03,,77
,Reward Design with Language Models,Reward Design with Language Models,"Agent, Reinforcement-Learning, Reward",https://arxiv.org/abs/2303.00001,,,,2023/02/27,Reinforcement Learning,76
,Reflexion,Reflexion: Language Agents with Verbal Reinforcement Learning,Robot,https://arxiv.org/abs/2303.11366,,,,2023/03/20,Self-improvement,74
,ChatBridge,ChatBridge: Bridging Modalities with Large Language Model as a Language Catalyst,"LLM, Open-source",https://arxiv.org/abs/2305.16103,,,,2023/05/25,Open sourced LLM,73
,PointCLIP,PointCLIP: Point Cloud Understanding by CLIP,Perception,https://arxiv.org/abs/2112.02413,,,,2021/12/04,Object Detection,72
,Gensim,GenSim: Generating Robotic Simulation Tasks via Large Language Models,"Data-generation, Robot",https://arxiv.org/abs/2310.01361,,,,2023/10/02,Data generation,71
,Self-Polish,Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement,"Chain-of-Thought, In-Context-Learning, Self",https://arxiv.org/abs/2305.14497,,,,2023/05/23,Reasoning,70
,VisualCOMET,VisualCOMET: Reasoning about the Dynamic Context of a Still Image,"In-Context-Learning, VQA",https://arxiv.org/abs/2004.10796,,,,2020/04/22,Reasoning,69
,Generative Agents,Generative Agents: Interactive Simulacra of Human Behavior,In-Context-Learning,https://arxiv.org/abs/2304.03442,,,,2023/04/07,Memory,68
,Flamingo,Flamingo: a Visual Language Model for Few-Shot Learning,"Multimodal, Robot",https://arxiv.org/abs/2204.14198,,,,2022/04/29,Multimodal LLM,67
,Text2Reward,Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning,"Agent, Reinforcement-Learning, Reward",https://arxiv.org/abs/2309.11489,,,,2023/09/20,Reinforcement Learning,66
,3D-LLM,3D-LLM: Injecting the 3D World into Large Language Models,"3D, Open-source, Perception, Robot",https://arxiv.org/abs/2307.12981,,,,2023/07/24,Multimodal Data injection,65
,Plan-and-Solve,Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2305.04091,,,,2023/05/06,Reasoning,64
,Eureka,Eureka: Human-Level Reward Design via Coding Large Language Models,"Agent, Reinforcement-Learning",https://arxiv.org/abs/2310.12931,,,,2023/10/19,Reinforcement Learning,63
,Voyager,Voyager: An Open-Ended Embodied Agent with Large Language Models,"Agent, Minecraft",https://arxiv.org/abs/2305.16291,,,,2023/05/25,Planning,62
,Tree of Thought,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2305.10601,,,,2023/05/17,Chain of Thought,61
,Maieutic Prompting,Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2205.11822,,,,2022/05/24,Reasoning,60
,VIMA,VIMA: General Robot Manipulation with Multimodal Prompts,"End2End, Multimodal, Robot",https://arxiv.org/abs/2210.03094,,,,2022/10/06,Multimodal prompts,59
,A Survey of Large Language Models,A Survey of Large Language Models,"LLM, Survey",https://arxiv.org/abs/2303.18223,,,,2023/03/31,Survey Papers,58
,Path planners,Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning,"LLM, Spacial",https://arxiv.org/abs/2310.03249,,,,2023/10/05,Spatial Understanding,57
,SMART-LLM,SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models,"Code-as-Policies, Robot",https://arxiv.org/abs/2309.10062,,,,2023/09/18,Code generation,56
,CogVLM,CogVLM: Visual Expert for Pretrained Language Models,"VLM, VQA",https://arxiv.org/abs/2311.03079,,,,2023/11/06,Visual Question Answering,55
,PaLM-E,PaLM-E: An Embodied Multimodal Language Model,"End2End, Multimodal, Robot",https://arxiv.org/abs/2303.03378,,,,2023/03/06,Multimodal LLM,54
,Auto-CoT,Automatic Chain of Thought Prompting in Large Language Models,"Automate, Chain-of-Thought, Reasoning",https://arxiv.org/abs/2210.03493,,,,2022/10/07,Chain of Thought,53
,PAL,PAL: Program-aided Language Models,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2211.10435,,,,2022/11/18,Reasoning,52
,Self-Refine,Self-Refine: Iterative Refinement with Self-Feedback,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2303.17651,,,,2023/03/30,Reasoning,51
,NL2TL,NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models,"LLM, Temporal Logics",https://arxiv.org/abs/2305.07766,,,,2023/05/12,Temporal Logics,50
20,Gpt-driver,GPT-Driver: Learning to Drive with GPT,"Driving, Spacial",https://arxiv.org/abs/2310.01415,,https://pointscoder.github.io/projects/gpt_driver/static/images/Arch5.png,,2023/10/02,Spatial Understanding,49
,Reasoning in Large Language Models,Towards Reasoning in Large Language Models: A Survey,"LLM, Reasoning, Survey",https://arxiv.org/abs/2212.10403,,,,2022/12/20,Survey Paper,48
,DEPS,"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents","Agent, Minecraft",https://arxiv.org/abs/2302.01560,,,,2023/02/03,Planning,47
,PaLM,PaLM: Scaling Language Modeling with Pathways,VLM,https://arxiv.org/abs/2204.02311,,,,2022/04/05,Vision-LLM,46
,OpenFlamingo,OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models,"LLM, Open-source",https://arxiv.org/abs/2308.01390,,,,2023/08/02,Open sourced LLM,45
,Gemini vs GPT-4V,Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases,"GPT4, Gemini, LLM",https://arxiv.org/abs/2312.15011,,,,2023/12/22,Quantitive Analysis,44
,LLaVA,Visual Instruction Tuning,"Instruction-Turning, LLM, PEFT",https://arxiv.org/abs/2304.08485,,,,2023/04/17,,43
,SuperICL,Small Models are Valuable Plug-ins for Large Language Models,In-Context-Learning,https://arxiv.org/abs/2305.08848,,,,2023/05/15,Reasoning,42
,MOO,Open-World Object Manipulation using Pre-trained Vision-Language Models,"Multimodal, Robot",https://arxiv.org/abs/2303.00905,,,,2023/03/02,Multimodal LLM,41
,AgentInstruct,Agent Instructs Large Language Models to be General Zero-Shot Reasoners,"Agent, Reasoning, Zero-shot",https://arxiv.org/abs/2310.03710,,,,2023/10/05,Planning,40
,AdaRefiner,AdaRefiner: Refining Decisions of Language Models with Adaptive Feedback,"Agent, Feedback, Reinforcement-Learning",https://arxiv.org/abs/2309.17176,,,,2023/09/29,Reinforcement Learning,39
,Toward General-Purpose,Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis,"Robot, Survey",https://arxiv.org/abs/2312.08782,,,,2023/12/14,Survey papers,38
,Self-supervised ICL,SINC: Self-Supervised In-Context Learning for Vision-Language Tasks,"In-Context-Learning, VQA",https://arxiv.org/abs/2307.07742,,,,2023/07/15,Self-supervised,37
,Self-Ask,Measuring and Narrowing the Compositionality Gap in Language Models,"Chain-of-Thought, In-Context-Learning, Self",https://arxiv.org/abs/2210.03350,,,,2022/10/07,Reasoning,36
,COMPLEXITY-CoT,Complexity-Based Prompting for Multi-Step Reasoning,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2210.00720,,,,2022/10/03,Reasoning,35
,Algorithm of Thoughts,Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2308.10379,,,,2023/08/20,Reasoning,34
,GPT4-V OpenFlamingo,OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models,"Open-source, VLM",https://arxiv.org/abs/2308.01390,,,,2023/08/02,Vision-LLM,33
,Physically Grounded Vision-Language Model,Physically Grounded Vision-Language Models for Robotic Manipulation,"End2End, Multimodal, Robot",https://arxiv.org/abs/2309.02561,,,,2023/09/05,Multimodal LLM,32
,Prompt a Robot to Walk,Prompt a Robot to Walk with Large Language Models,"Low-level-action, Robot",https://arxiv.org/abs/2309.09969,,,,2023/09/18,Low-level output,31
90,Large Language Model Based Agents,The Rise and Potential of Large Language Model Based Agents: A Survey,"Agent, Survey",https://arxiv.org/abs/2309.07864,,,,2023/09/14,Survey Paper,30
,Chameleon,Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models,"VLM, VQA",https://arxiv.org/abs/2304.09842,,,,2023/04/19,Visual Question Answering,29
,BIG-Bench,Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models,In-Context-Learning,https://arxiv.org/abs/2206.04615,,,,2022/06/09,Benchmark,28
,JARVIS-1,JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models,"Agent, Memory, Minecraft",https://arxiv.org/abs/2311.05997,,,,2023/11/10,Planning,27
,Verify-and-Edit,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2305.03268,,,,2023/05/05,Chain of Thought,26
,Least-to-Most Prompting,Least-to-Most Prompting Enables Complex Reasoning in Large Language Models,"Chain-of-Thought, In-Context-Learning",https://arxiv.org/abs/2205.10625,,,,2022/05/21,Reasoning,25
,MM-ReAct,MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,"Reasoning, VLM, VQA",https://arxiv.org/abs/2303.11381,,,,2023/03/20,Visual Question Answering,24
,RLAdapter,RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds,"Agent, Minecraft, Reinforcement-Learning",,,,,,Reinforcement Learning,23
,Segment Anything,Segment Anything,"LLM, Open-source, Perception, Segmentation",https://arxiv.org/abs/2304.02643,,https://images.ctfassets.net/mauam998hl9x/L9hdF333CFCsBTSlYC7ey/b40a451118b366b1f4a5fccecb62971a/main.jpg,,2023/04/05,Object Detection,22
,MiniGPT-4,MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models,"Instruction-Turning, LLM",https://arxiv.org/abs/2304.10592,,,,2023/04/20,,21
,Lafite-RL,Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models,"Agent, Feedback, Reinforcement-Learning, Robot",https://arxiv.org/abs/2311.02379,,,,2023/11/04,Reinforcement Learning,20
,Embodied Task Planning,Embodied Task Planning with Large Language Models,"Embodied, Robot, Task-Decompose",https://arxiv.org/abs/2307.01848,,,,2023/07/04,Planning,19
,GPT4Vis,GPT4Vis: What Can GPT-4 Do for Zero-shot Visual Recognition?,"LLM, Zero-shot",https://arxiv.org/abs/2311.15732,,,,2023/11/27,Quantitive Analysis,18
,OWL-ViT,Simple Open-Vocabulary Object Detection with Vision Transformers,Perception,https://arxiv.org/abs/2205.06230,,,,2022/05/12,Object Detection,17
,AgentSims,AgentSims: An Open-Source Sandbox for Large Language Model Evaluation,Agent,https://arxiv.org/abs/2308.04026,,,,2023/08/08,Open-Source Evaluation,16
50,Chain of Thought,Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,"Chain-of-Thought, Reasoning",https://arxiv.org/abs/2201.11903,,,,2022/01/28,Chain of Thought,15
,DOREMI,DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment,"Perception, Task-Decompose",https://arxiv.org/abs/2307.00329,,,,2023/07/01,Decomposing task,14
,Autonomous Agents,A Survey on Large Language Model based Autonomous Agents,"Agent, Survey",https://arxiv.org/abs/2308.11432,,,,2023/08/22,Planning,13
,REFLECT,REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction,"Feedback, Robot",https://arxiv.org/abs/2306.15724,,,,2023/06/27,Self-improvement,12
,The Development of LLMs,The Development of LLMs for Embodied Navigation,"Embodied, LLM, Robot, Survey",https://arxiv.org/abs/2311.00530,,,,2023/11/01,Survey papers,11
,Code as policies,Code as Policies: Language Model Programs for Embodied Control,"Code-as-Policies, Embodied, PersonalCitation, Robot",https://arxiv.org/abs/2209.07753,,https://code-as-policies.github.io/img/share_image.png,,2022/09/16,Code generation,10
,InternGPT,InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language,"Intaractive, OpenGVLab, VLM",https://arxiv.org/abs/2305.05662,,,,2023/05/09,Vision-LLM,9
,ELLM,Guiding Pretraining in Reinforcement Learning with Large Language Models,"Agent, Reinforcement-Learning",https://arxiv.org/abs/2302.06692,,,,2023/02/13,Reinforcement Learning,8
,Caption Anything,Caption Anything: Interactive Image Description with Diverse Multimodal Controls,"Caption, VLM, VQA",https://arxiv.org/abs/2305.02677,,,,2023/05/04,Visual Question Answering,7
,Language to Rewards,Language to Rewards for Robotic Skill Synthesis,"Agent, Reinforcement-Learning",https://arxiv.org/abs/2306.08647,,,,2023/06/14,Reinforcement Learning,6
,MOMA-Force,MOMA-Force: Visual-Force Imitation for Real-World Mobile Manipulation,"Multimodal, Robot",https://arxiv.org/abs/2308.03624,,,,2023/08/07,Multimodal prompts,5
,ViperGPT,ViperGPT: Visual Inference via Python Execution for Reasoning,"Code-as-Policies, Reasoning, VLM, VQA",https://arxiv.org/abs/2303.08128,,,,2023/03/14,Visual Question Answering,4
,Robot Learning,Robot Learning in the Era of Foundation Models: A Survey,"Robot, Survey",https://arxiv.org/abs/2311.14379,,,,2023/11/24,Survey papers,3
,SelfCheck,SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning,"Chain-of-Thought, Planning, Reasoning",https://arxiv.org/abs/2308.00436,,,,2023/08/01,Planning,2
,A Survey of Chain of Thought Reasoning,"A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future","Chain-of-Thought, Reasoning, Survey",https://arxiv.org/abs/2309.15402,,,,2023/09/27,Survey Paper,1